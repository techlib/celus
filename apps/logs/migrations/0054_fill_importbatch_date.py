# Generated by Django 3.2.12 on 2022-02-15 11:11
import sys

from django.db import migrations
from django.db.models import Count, F, Max, Min


def fix_extra_month_in_jr2_data(apps, schema_editor):
    """
    Pycounter contained an error which caused data from JR2 reports to create an extra month
    beyond the one that was present
    (https://github.com/pitthsls/pycounter/commit/7c24ab91460c25a8b9d905b0484f375d27841ac2)
    This code find and, if `fix` is True, fixes the problem.

    Because it works on AccessLog level, it has to deal with Clickhouse
    """
    ReportType = apps.get_model('logs', 'ReportType')
    AccessLog = apps.get_model('logs', 'AccessLog')
    SushiFetchAttempt = apps.get_model('sushi', 'SushiFetchAttempt')
    try:
        jr2 = ReportType.objects.get(short_name='JR2')
    except ReportType.DoesNotExist:
        return
    import_batches = (
        AccessLog.objects.filter(report_type=jr2)
        .values('import_batch_id')
        .annotate(month_count=Count('date', distinct=True))
        .filter(month_count__gt=1)
    )
    count = 0
    from django.conf import settings

    for rec in import_batches:
        ib_id = rec['import_batch_id']
        try:
            fa = SushiFetchAttempt.objects.get(import_batch_id=ib_id)
        except SushiFetchAttempt.DoesNotExist:
            # we are only interest in import batches with fetch attempt, because there we can check
            # the expected date
            continue

        # delete access logs for which the date does not match the fetch attempt
        AccessLog.objects.filter(import_batch_id=ib_id).exclude(date=fa.start_date).delete()
        if settings.CLICKHOUSE_SYNC_ACTIVE:
            from logs.cubes import AccessLogCube, ch_backend

            ch_backend.delete_records(
                AccessLogCube.query().filter(import_batch_id=ib_id, date__not_in=[fa.start_date])
            )
        count += 1
    print(f'Fixed {count} broken JR2 import batches')


def fix_unrequested_data_in_import_batches(apps, schema_editor):
    """
    In FLVC we got 2 import batches where the sushi server gave us not only data for the
    period we asked for, but also for other periods :/
    Here we find and fix such cases. We need the fetch attempt for that, because we need to know
    the requested date

    Because it works on AccessLog level, it has to deal with Clickhouse
    """
    AccessLog = apps.get_model('logs', 'AccessLog')
    ImportBatch = apps.get_model('logs', 'ImportBatch')
    import_batches = (
        AccessLog.objects.values('import_batch_id')
        .annotate(month_count=Count('date', distinct=True))
        .filter(month_count__gt=1)
        .values('import_batch_id')
    )
    count = 0
    from django.conf import settings

    for ib in ImportBatch.objects.filter(
        pk__in=import_batches, sushifetchattempt__isnull=False
    ).select_related('sushifetchattempt'):
        ib.date = ib.sushifetchattempt.start_date
        ib.save()
        # delete access logs for which the date does not match the fetch attempt
        AccessLog.objects.filter(import_batch_id=ib.pk).exclude(date=ib.date).delete()
        if settings.CLICKHOUSE_SYNC_ACTIVE:
            from logs.cubes import AccessLogCube, ch_backend

            ch_backend.delete_records(
                AccessLogCube.query().filter(import_batch_id=ib.pk, date__not_in=[ib.date])
            )
        count += 1
    print(f'Fixed {count} import batches with extra data')


def add_date_to_importbatch_from_fetchattempts(apps, schema_editor):
    """
    Assign date to import batch based on the fetch attempt - this is much faster than using
    accesslogs
    """
    ImportBatch = apps.get_model('logs', 'ImportBatch')
    SushiFetchAttempt = apps.get_model('sushi', 'SushiFetchAttempt')
    # a sanity check first
    multi_month = (
        ImportBatch.objects.annotate(start=Min('accesslog__date'), end=Max('accesslog__date'))
        .exclude(end=F('start'))
        .count()
    )
    if multi_month:
        raise ValueError(
            f'Multi-month import batches exist ({multi_month}), migration cannot proceed!'
        )
    total = 0
    # it is not possible to use F() with join in updates, so we cannot update all importbatches
    # with the date extracted from FetchAttempt. Therefor we do it at least in batches by month
    # which is much more effective than doing it import batch by import batch
    print('Import batches without date:', ImportBatch.objects.filter(date__isnull=True).count())
    # we need the import_batch__isnull=False because the import_batch__date__isnull may be caused
    # by import_batch being null (a left outer join is created), so the filter would not work as
    # expected
    for month in (
        SushiFetchAttempt.objects.filter(
            import_batch__date__isnull=True, import_batch__isnull=False
        )
        .values_list('start_date', flat=True)
        .distinct()
    ):
        updated = ImportBatch.objects.filter(
            date__isnull=True,
            pk__in=SushiFetchAttempt.objects.filter(start_date=month)
            .values('import_batch_id')
            .distinct(),
        ).update(date=month)
        total += updated
        print(f'Updated import batches for {month}: {updated}')
    print(f'Updated import batches - total: {total}')
    print(
        f'Left import batches without date:', ImportBatch.objects.filter(date__isnull=True).count()
    )


def add_date_to_importbatch_from_accesslogs(apps, schema_editor):
    ImportBatch = apps.get_model('logs', 'ImportBatch')
    # it is not possible to use F() with joint in updates, so we cannot update all import batches
    # with the date extracted from AccessLogs. Here we use a naive approach which goes by
    # individual import batches, because we can assume only a small number of objects here
    # because most will be resolved above using fetch attempts
    total = 0
    print('Import batches without date:', ImportBatch.objects.filter(date__isnull=True).count())
    for ib in (
        ImportBatch.objects.filter(date__isnull=True)
        .annotate(al_date=Min('accesslog__date'))
        .filter(al_date__isnull=False)
    ):
        ib.date = ib.al_date
        ib.save()
        total += 1
        print('.', end='')
        sys.stdout.flush()
    print(f'Updated import batches - total: {total}')
    print(
        f'Left import batches without date:', ImportBatch.objects.filter(date__isnull=True).count()
    )


def remove_orphan_import_batches_without_date(apps, schema_editor):
    """
    If any import batches still exist which do not have date, they should not have a fetch attempt
    and have empty usage - and thus not have much value.
    Here we remove those that do not have an MDU.
    """
    ImportBatch = apps.get_model('logs', 'ImportBatch')
    removed, stats = (
        ImportBatch.objects.filter(
            date__isnull=True, sushifetchattempt__isnull=True, mdu__isnull=True
        )
        .annotate(al_count=Count('accesslog'))
        .filter(al_count=0)
        .delete()
    )
    print(f'Removed {removed} import batches without MDU and with zero usage')
    without_date = ImportBatch.objects.filter(date__isnull=True).count()
    print(f'Left import batches without date: {without_date}  - these are from empty MDUs')


class Migration(migrations.Migration):

    dependencies = [
        ('logs', '0053_clickhouse_add_import_batch_idx'),
        ('sushi', '0048_discard_credentials_broken_state'),
        ('scheduler', '0014_finalizing_import_batch'),
    ]

    operations = [
        migrations.RunPython(fix_extra_month_in_jr2_data, migrations.RunPython.noop),
        migrations.RunPython(fix_unrequested_data_in_import_batches, migrations.RunPython.noop),
        # we need to use both fetch attempts and accesslogs for adding dates because
        # none of them alone works for all import batches
        migrations.RunPython(add_date_to_importbatch_from_fetchattempts, migrations.RunPython.noop),
        migrations.RunPython(add_date_to_importbatch_from_accesslogs, migrations.RunPython.noop),
        # we finally remove import batches which are empty and completely orphaned
        migrations.RunPython(remove_orphan_import_batches_without_date, migrations.RunPython.noop),
    ]
